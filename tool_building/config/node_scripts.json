{
    "router": {
        "script": "from swarm.swarm import Swarm\nasync def router(goal):\n    swarm = Swarm()\n    router_agent = swarm.agents['router']\n    options = ['user_assistance', 'python_coder', 'manager', 'writer', 'retrieval']\n    \n    agent_index = await router_agent.chat(goal)\n    agent_index = agent_index['arguments']['agent_index']\n    \n    if agent_index == 0: # User assistance\n        while True:\n            user_input = input(f\"The router agent needs assistance routing this goal:\\n\\n{goal}\\n\\nPlease choose the index of the agent this goal should be routed to: {options}\")\n            if user_input.isdigit():\n                user_number = int(user_input)\n                if 1 <= user_number <= len(options):\n                    print(f\"You chose the number: {user_number}\")\n                    agent_index = user_number\n                    break\n                else:\n                    print(\"Number out of range. Please try again. Don't select user_assistance again.\")\n            else:\n                print(\"Invalid input. Please enter a number.\")\n                \n    node_blueprints = [{'type': options[agent_index], 'data': {'goal': goal}}]\n    return {'action': 'spawn', 'node_blueprints': node_blueprints}\n",
        "description": "Routes a task to the appropriate next action.\n\tInput: A list of subtasks (list), a string describing the context of the goal (str), and a boolean indicating whether the subtasks should be executed in parallel or sequentially (bool)\n\tReturns: None\nCalls the subtask_router_agent to route a subtask to the appropriate next action. Schedules tasks in swarm correspondingly:\nA dictionary with the following keys:\n\t'next_action': An integer indicating the next action to take (1: break_down_goal, 2: write_text, 3: write_python, 4: retrieve_info, 5: ask_user_for_help)",
        "language": "python"
    },
    "manager": {
        "script": "from swarm.swarm import Swarm\nasync def manager(goal):\n    swarm = Swarm()\n    manager = swarm.agents['manager']\n    \n    while True:\n        broken_down_goal = await manager.chat(goal)\n        agent_has_questions = broken_down_goal['arguments']['do_you_have_questions']\n\n        if agent_has_questions:\n            question = broken_down_goal['arguments']['question']\n            user_input = input(f\"\\n\\nQuestions: {question}\\n\\nGoal: {goal}\\n\\n\")\n            goal = f'{goal}\\n\\nQuestion: {question} \\n\\nUser answer: {user_input}'\n        else:\n            subgoals = broken_down_goal['arguments']['subgoals']\n            break\n            \n    node_blueprints = []\n    for subgoal in subgoals:\n        node_blueprints.append({'type': 'router', 'data': {'goal': subgoal}})\n\n    return {'action': 'spawn', 'node_blueprints': node_blueprints}\n",
        "description": "Breaks down a goal into subtasks.\n\tInput: Any arbitray goal (str)\n\tReturns: None\nCalls the head_agent to break down the goal. Then, calls the router_agent to route subtasks to the appropriate next action. Passes this to router from head_agent:\nA dictionary with the following keys:\n\t'subtasks': A list of subtasks (str)\n\t'context': A string describing the context of the goal\n\t'is_parallel': A boolean indicating whether the subtasks should be executed in parallel or sequentially",
        "language": "python"
    },
    "python_coder": {
        "script": "from swarm.swarm import Swarm\nfrom settings import Settings\nimport json\nsettings = Settings() # For config paths\n\nasync def python_coder(goal):\n    swarm = Swarm()\n    \n    # Gather all relevant context\n    code_analyst = swarm.agents['code_analyst']\n    while True:\n        questions = await code_analyst.chat(goal)\n        analyst_has_questions = questions['arguments']['do_you_have_questions']\n        \n        if analyst_has_questions:\n            questions = questions['arguments']['questions']\n            user_input = input(f\"\\n\\nGoal: {goal}\\n\\nQuestions: {questions}\\n\")\n            goal = f'{goal}\\n\\nQuestions: {questions} \\n\\nUser answer: {user_input}'\n        else: \n            break\n\n    # Write code\n    python_coder = swarm.agents['python_coder']\n    code = await python_coder.chat(goal)\n    code = code['arguments']['python_code']\n    python_metadata_extractor = swarm.agents['python_metadata_extractor']\n    metadata = await python_metadata_extractor.chat(code)\n    name = metadata['arguments']['name']\n    code_type = ['function', 'class', 'script', 'other']\n    packet = {\n        'language': 'python',\n        'code_type': code_type[metadata['arguments']['code_type']],\n        'code': code,\n        'description': metadata['arguments']['description'],\n        'dependencies': metadata['arguments'].get('dependencies', [])\n    }\n\n    file_name = settings.SYNTHETIC_CODE_PATH\n    with open(file_name, 'r') as file:\n        data = json.load(file)\n    data[name] = packet\n    with open(file_name, 'w') as file:\n        json.dump(data, file, indent=4)\n\n    node_blueprints = [{'type': 'python_script_tester', 'data': {'code_key': name}}]\n    return {'action': 'spawn', 'node_blueprints': node_blueprints}    \n",
        "description": "",
        "language": ""
    },
    "python_script_tester": {
        "script": "from settings import Settings\nimport json\nfrom swarm.swarm import Swarm\nimport os\nfrom swarm.memory.testing_ground.python_scripts.schema import python_script_test_result_template\nimport asyncio\n\nsettings = Settings()\n\ndef load_json_data(path):\n    with open(path, 'r') as file:\n        return json.load(file)\n      \ndef save_progress(code_key, updates):\n    try:\n        data = load_json_data(settings.PYTHON_SCRIPT_TEST_RESULTS_PATH)\n    except (FileNotFoundError, json.JSONDecodeError):\n        data = {}\n\n    # If code_key is new, initialize it using the template\n    if code_key not in data:\n        data[code_key] = python_script_test_result_template.copy()\n\n    # Recursive function to update the dictionary\n    def update_dict(d, u):\n        for k, v in u.items():\n            if isinstance(v, dict):\n                d[k] = update_dict(d.get(k, {}), v)\n            else:\n                d[k] = v\n        return d\n\n    # Update the data\n    data[code_key] = update_dict(data[code_key], updates)\n\n    # Save the updated data back to the file\n    with open(settings.PYTHON_SCRIPT_TEST_RESULTS_PATH, 'w') as file:\n        json.dump(data, file, indent=4)\n        \nasync def async_input(prompt: str = \"\") -> str:\n    loop = asyncio.get_event_loop()\n    return await loop.run_in_executor(None, input, prompt)\n\nasync def assess_script(code_key, script_message, swarm):\n    python_script_assessor_pre_testing = swarm.agents['python_script_assessor_pre_testing']\n    script_assessment = await python_script_assessor_pre_testing.chat(script_message)\n    save_progress(code_key, {'autonomous_testing': {'script_assessment': script_assessment['arguments']}})\n    return script_assessment\n\nasync def generate_test_script(code_key, script_assessment, script_message, code, swarm):\n    executable_python_test_script_generator = swarm.agents['executable_python_test_script_generator']\n    if script_assessment['arguments']['is_script_runnable_as_is']:\n        script_message += '\\n<Script is runnable as is.>\\n'\n    else: \n        script_message += (\n            '\\n<Script is not runnable as is. You need to leave the script unchanged, '\n            'adding logic to execute and fill in blank parameters as necessary.>\\n'\n        )\n        if script_assessment['arguments'].get('needs_user_provided_parameters', False):\n            user_input = await async_input(\n                \"\\n\\nThe python script tester needs you to provide input parameters to test this script: \"\n                f\"\\n{code}\\n\\nPlease provide the name of the parameters followed by the value.\"\n            )\n            script_message += f'<USER PARAMS>\\n{user_input}\\n<USER PARAMS ENDS>\\n'\n    script_message += (\n        f\"\\n**Success Logging Params**:\\n\"\n        f\"JSON_SAVE_SUCCESS_PATH = '{settings.AUTONOMOUS_SCRIPT_TESTS_PATH}'\\n\"\n        f\"SCRIPT_KEY = '{code_key}'\"\n    )\n    executable_script = await executable_python_test_script_generator.chat(script_message)\n    save_progress(code_key, {'autonomous_testing': {'executable_script': executable_script['arguments']}})\n    return executable_script\n\nasync def try_executing_synthetic_script(code_key, executable_script):\n    try: \n        exec(executable_script['arguments']['executable_script'])  \n    except Exception as e:\n        error_message = f\"Error executing script {code_key}: {e}\"\n        save_progress(code_key, {'autonomous_testing': {'error': error_message}})\n        raise Exception(error_message)\n\nasync def manually_prepare_script_for_testing(code_key, script_message):\n    manual_test_file_path = f'{settings.MANUAL_PATH}/{code_key}.py'\n    save_progress(code_key, {'manual_testing': {'manual_test_file_path': manual_test_file_path}})\n    if not os.path.exists(manual_test_file_path):\n        open(manual_test_file_path, 'w').close()\n    with open(manual_test_file_path, 'w') as file:\n        file.write(script_message)\n    await async_input(\n        f'\\nThe autonomous script tester failed. Please manually prepare the script for testing at {manual_test_file_path} '\n        f'and press enter when ready.\\nAdd logic to save the result of the successful test in {settings.MANUAL_SCRIPT_TESTS_PATH} file as follows:\\n'\n        f'Prepare a success message that includes two dictionaries:\\n'\n        f'- input: Containing the parameters used for the test.\\n'\n        f'- output: Detailing the results or outputs from the test execution.\\n'\n        f'These will be added to a JSON file so make sure they are serializable. Leave out non-serializable data.\\n'\n        f'Save the success dict to the file: {settings.MANUAL_SCRIPT_TESTS_PATH} with the key: {code_key}\\n\\n'\n        f'Press enter when ready.\\n'\n    )\n    return\n\nasync def try_executing_manually_prepared_script(code_key):\n    try:\n        with open(f'{settings.MANUAL_TESTING_GROUND_FOLDER_PATH}/{code_key}.py', 'r') as file:\n            manually_prepared_test_script = file.read()\n            save_progress(code_key, {'manual_testing': {'manually_prepared_test_script': manually_prepared_test_script}})\n            exec(manually_prepared_test_script)\n    except Exception as e:\n        error_message = f\"Error executing script {code_key}: {e}\"\n        save_progress(code_key, {'manual_testing': {'error': error_message}})\n        raise Exception(error_message)\n\nasync def python_script_tester(code_key):  \n    swarm = Swarm()\n    # Load the script to be tested\n    synthetic_code_database = load_json_data(settings.SYNTHETIC_CODE_PATH)\n    code = synthetic_code_database[code_key]['code']\n    script_message = (\n        f'<CODE STARTS>\\n{synthetic_code_database[code_key][\"code\"]}\\n<CODE ENDS>\\n'\n        f'<DESCRIPTION STARTS>\\n{synthetic_code_database[code_key][\"description\"]}\\n<DESCRIPTION ENDS>\\n'\n    )\n    save_progress(code_key, {'original_script': script_message})\n\n    try: # autonomously preparing and testing the script\n        script_assessment = await assess_script(code_key, script_message, swarm)\n        executable_script = await generate_test_script(code_key, script_assessment, script_message, code, swarm)\n        await try_executing_synthetic_script(executable_script)\n    except: # manually prepare and test the script\n        manually_prepare_script_for_testing(code_key, script_message)\n        await try_executing_manually_prepared_script(code_key)\n\n    return {'action': 'terminate', 'node_blueprints': []}\n",
        "description": "",
        "language": ""
    }
}